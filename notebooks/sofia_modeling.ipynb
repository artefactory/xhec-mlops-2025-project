{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f6c1e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Abalone Age Prediction - ML Modeling Pipeline\n",
    "\n",
    "# This notebook contains the complete machine learning pipeline for predicting abalone age from physical measurements.\n",
    "\n",
    "# ## Objective\n",
    "# Build a robust ML pipeline with:\n",
    "# - Data preprocessing functions\n",
    "# - Model training with Random Forest\n",
    "# - Comprehensive evaluation metrics\n",
    "# - Prediction pipeline for new data\n",
    "\n",
    "# **Target**: Predict the number of rings (age indicator) from physical measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8655f8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Abalone Age Prediction - ML Pipeline\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Abalone Age Prediction - Simple MLflow Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"🎯 Simple Abalone Age Prediction with MLflow\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c367a38",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Inspection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a986e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup MLflow\n",
    "mlflow.set_experiment(\"abalone_age_prediction\")\n",
    "\n",
    "def inspect_data(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Perform comprehensive data inspection.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataset to inspect\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, Any]: Inspection summary\n",
    "    \"\"\"\n",
    "    print(\"\\n🔍 Data Inspection Report\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    inspection = {}\n",
    "    \n",
    "    # Basic info\n",
    "    inspection['shape'] = df.shape\n",
    "    inspection['memory_usage'] = df.memory_usage(deep=True).sum() / 1024**2  # MB\n",
    "    \n",
    "    # Missing values\n",
    "    missing = df.isnull().sum()\n",
    "    inspection['missing_values'] = missing[missing > 0].to_dict()\n",
    "    \n",
    "    # Duplicates\n",
    "    inspection['duplicates'] = df.duplicated().sum()\n",
    "    \n",
    "    # Data types\n",
    "    inspection['dtypes'] = df.dtypes.to_dict()\n",
    "    \n",
    "    # Basic statistics for numerical columns\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    inspection['numerical_summary'] = df[numerical_cols].describe().to_dict()\n",
    "    \n",
    "    # Categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    inspection['categorical_summary'] = {}\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        inspection['categorical_summary'][col] = {\n",
    "            'unique_values': df[col].unique().tolist(),\n",
    "            'value_counts': df[col].value_counts().to_dict()\n",
    "        }\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"📊 Shape: {inspection['shape']}\")\n",
    "    print(f\"💾 Memory usage: {inspection['memory_usage']:.2f} MB\")\n",
    "    print(f\"❓ Missing values: {len(inspection['missing_values'])} columns affected\")\n",
    "    print(f\"🔄 Duplicate rows: {inspection['duplicates']}\")\n",
    "    \n",
    "    if inspection['missing_values']:\n",
    "        print(\"Missing data details:\")\n",
    "        for col, count in inspection['missing_values'].items():\n",
    "            print(f\"  - {col}: {count} missing\")\n",
    "    \n",
    "    return inspection\n",
    "\n",
    "# Load and inspect the data\n",
    "df = load_data('../data/abalone.csv')\n",
    "data_inspection = inspect_data(df)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\n📋 First 5 rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1f0be1",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92c74499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore the data\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load and inspect abalone dataset.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"📂 Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"\\nTarget variable (Rings) summary:\")\n",
    "    print(f\"Min: {df['Rings'].min()}, Max: {df['Rings'].max()}, Mean: {df['Rings'].mean():.2f}\")\n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "df = load_data('../data/abalone.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"\\n\udccb First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(f\"\\n📊 Dataset info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Apply preprocessing to the loaded data\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🔄 PREPROCESSING PIPELINE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Clean the data\n",
    "df_clean = clean_data(df)\n",
    "\n",
    "# Encode categorical features\n",
    "df_encoded, encoders = encode_categorical_features(df_clean)\n",
    "\n",
    "# Engineer features\n",
    "df_features = feature_engineering(df_encoded)\n",
    "\n",
    "print(f\"\\n✅ Preprocessing complete!\")\n",
    "print(f\"   Original columns: {len(df.columns)}\")\n",
    "print(f\"   Final columns: {len(df_features.columns)}\")\n",
    "print(f\"   Final dataset shape: {df_features.shape}\")\n",
    "\n",
    "# Display the processed data\n",
    "print(\"\\n📋 Processed data sample:\")\n",
    "display(df_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692486af",
   "metadata": {},
   "source": [
    "## 3. Data Splitting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf03c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple data preprocessing\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Simple preprocessing without complex feature engineering.\"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Encode Sex column (M, F, I -> 0, 1, 2)\n",
    "    le = LabelEncoder()\n",
    "    df_processed['Sex_encoded'] = le.fit_transform(df_processed['Sex'])\n",
    "    df_processed = df_processed.drop('Sex', axis=1)\n",
    "    \n",
    "    print(f\"✅ Encoded Sex column: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df_processed.drop('Rings', axis=1)\n",
    "    y = df_processed['Rings']\n",
    "    \n",
    "    print(f\"📊 Features shape: {X.shape}\")\n",
    "    print(f\"🎯 Target shape: {y.shape}\")\n",
    "    \n",
    "    return X, y, le\n",
    "\n",
    "# Preprocess data\n",
    "X, y, label_encoder = preprocess_data(df)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n📊 Data split:\")\n",
    "print(f\"Training: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Scale the features\n",
    "X_train_scaled, feature_scaler = scale_features(X_train, fit_scaler=True)\n",
    "X_test_scaled, _ = scale_features(X_test, fit_scaler=False, scaler=feature_scaler)\n",
    "\n",
    "print(f\"\\n✅ Data preparation complete!\")\n",
    "print(f\"   Training features: {X_train_scaled.shape}\")\n",
    "print(f\"   Test features: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc027e05",
   "metadata": {},
   "source": [
    "## 4. Model Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af26dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training with MLflow tracking\n",
    "def train_and_log_model(model, model_name, X_train, X_test, y_train, y_test, **params):\n",
    "    \"\"\"Train a model and log metrics with MLflow.\"\"\"\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Train model\n",
    "        print(f\"\\n🤖 Training {model_name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "        train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "        test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "        train_r2 = r2_score(y_train, y_train_pred)\n",
    "        test_r2 = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metrics({\n",
    "            \"train_rmse\": train_rmse,\n",
    "            \"test_rmse\": test_rmse,\n",
    "            \"train_mae\": train_mae,\n",
    "            \"test_mae\": test_mae,\n",
    "            \"train_r2\": train_r2,\n",
    "            \"test_r2\": test_r2,\n",
    "            \"overfitting_rmse\": train_rmse - test_rmse\n",
    "        })\n",
    "        \n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"  📊 Results for {model_name}:\")\n",
    "        print(f\"    Train RMSE: {train_rmse:.4f}\")\n",
    "        print(f\"    Test RMSE:  {test_rmse:.4f}\")\n",
    "        print(f\"    Test MAE:   {test_mae:.4f}\")\n",
    "        print(f\"    Test R²:    {test_r2:.4f}\")\n",
    "        \n",
    "        return model, {\n",
    "            'train_rmse': train_rmse,\n",
    "            'test_rmse': test_rmse,\n",
    "            'test_mae': test_mae,\n",
    "            'test_r2': test_r2\n",
    "        }\n",
    "\n",
    "# Train multiple models\n",
    "models_results = {}\n",
    "\n",
    "# 1. Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_trained, lr_metrics = train_and_log_model(\n",
    "    lr_model, \"Linear_Regression\", \n",
    "    X_train, X_test, y_train, y_test,\n",
    "    model_type=\"Linear Regression\"\n",
    ")\n",
    "models_results['Linear Regression'] = lr_metrics\n",
    "\n",
    "# 2. Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_trained, rf_metrics = train_and_log_model(\n",
    "    rf_model, \"Random_Forest\", \n",
    "    X_train, X_test, y_train, y_test,\n",
    "    model_type=\"Random Forest\",\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "models_results['Random Forest'] = rf_metrics\n",
    "\n",
    "# 3. Decision Tree\n",
    "dt_model = DecisionTreeRegressor(max_depth=10, random_state=42)\n",
    "dt_trained, dt_metrics = train_and_log_model(\n",
    "    dt_model, \"Decision_Tree\", \n",
    "    X_train, X_test, y_train, y_test,\n",
    "    model_type=\"Decision Tree\",\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "models_results['Decision Tree'] = dt_metrics\n",
    "\n",
    "# Display top feature importances\n",
    "print(f\"\\n🔝 Top 10 Feature Importances:\")\n",
    "top_features = training_info['feature_importance'].head(10)\n",
    "display(top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6ab164",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecbbe400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison and visualization\n",
    "def plot_model_comparison(models_results):\n",
    "    \"\"\"Create visualization comparing model performance.\"\"\"\n",
    "    \n",
    "    # Create comparison DataFrame\n",
    "    metrics_df = pd.DataFrame(models_results).T\n",
    "    print(\"📊 Model Comparison Table:\")\n",
    "    display(metrics_df.round(4))\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    models = list(models_results.keys())\n",
    "    test_rmse = [models_results[model]['test_rmse'] for model in models]\n",
    "    test_mae = [models_results[model]['test_mae'] for model in models]\n",
    "    test_r2 = [models_results[model]['test_r2'] for model in models]\n",
    "    \n",
    "    # RMSE comparison\n",
    "    axes[0].bar(models, test_rmse, color=['skyblue', 'lightgreen', 'salmon'])\n",
    "    axes[0].set_title('Test RMSE Comparison')\n",
    "    axes[0].set_ylabel('RMSE')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # MAE comparison\n",
    "    axes[1].bar(models, test_mae, color=['skyblue', 'lightgreen', 'salmon'])\n",
    "    axes[1].set_title('Test MAE Comparison')\n",
    "    axes[1].set_ylabel('MAE')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # R² comparison\n",
    "    axes[2].bar(models, test_r2, color=['skyblue', 'lightgreen', 'salmon'])\n",
    "    axes[2].set_title('Test R² Comparison')\n",
    "    axes[2].set_ylabel('R² Score')\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find best model\n",
    "    best_model = min(models_results.keys(), key=lambda x: models_results[x]['test_rmse'])\n",
    "    best_rmse = models_results[best_model]['test_rmse']\n",
    "    \n",
    "    print(f\"\\n🏆 Best Model: {best_model}\")\n",
    "    print(f\"   Best Test RMSE: {best_rmse:.4f}\")\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "# Compare models\n",
    "comparison_df = plot_model_comparison(models_results)\n",
    "\n",
    "# Comprehensive evaluation\n",
    "evaluation_metrics = evaluate_model(\n",
    "    model=model,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train\n",
    ")\n",
    "\n",
    "# Create evaluation visualizations\n",
    "plot_evaluation_charts(\n",
    "    model=model,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    feature_names=X_train_scaled.columns.tolist()\n",
    ")\n",
    "\n",
    "# Calculate permutation importance\n",
    "perm_importance = calculate_feature_importance_permutation(\n",
    "    model=model,\n",
    "    X_test=X_test_scaled,\n",
    "    y_test=y_test,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n🔝 Top 10 Permutation Feature Importances:\")\n",
    "display(perm_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1901e62c",
   "metadata": {},
   "source": [
    "## 6. Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7fc0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions and final evaluation\n",
    "def make_predictions_plot(model, X_test, y_test, model_name):\n",
    "    \"\"\"Create actual vs predicted plot.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.6, color='blue')\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel('Actual Rings')\n",
    "    plt.ylabel('Predicted Rings')\n",
    "    plt.title(f'Actual vs Predicted - {model_name}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add R² to plot\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    plt.text(0.05, 0.95, f'R² = {r2:.3f}', transform=plt.gca().transAxes,\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def preprocess_new_data(data: pd.DataFrame, \n",
    "                       encoders: Dict, \n",
    "                       scaler: StandardScaler) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess new data for prediction using fitted artifacts.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): New data to preprocess\n",
    "        encoders (Dict): Fitted encoders\n",
    "        scaler (StandardScaler): Fitted scaler\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed data ready for prediction\n",
    "    \"\"\"\n",
    "    print(\"🔧 Preprocessing new data for prediction...\")\n",
    "    \n",
    "    data_processed = data.copy()\n",
    "    \n",
    "    # Apply the same cleaning as training data (but don't remove outliers for new data)\n",
    "    # Just handle missing values\n",
    "    if data_processed.isnull().any().any():\n",
    "        print(\"   Warning: Found missing values in new data\")\n",
    "        # For prediction, you might want to handle this differently\n",
    "        data_processed = data_processed.fillna(data_processed.median())\n",
    "    \n",
    "    # Apply categorical encoding\n",
    "    if 'Sex' in data_processed.columns and 'Sex' in encoders:\n",
    "        # Encode Sex column\n",
    "        data_processed['Sex_encoded'] = encoders['Sex'].transform(data_processed['Sex'])\n",
    "        \n",
    "        # Create dummy variables\n",
    "        sex_dummies = pd.get_dummies(data_processed['Sex'], prefix='Sex')\n",
    "        data_processed = pd.concat([data_processed, sex_dummies], axis=1)\n",
    "        data_processed = data_processed.drop('Sex', axis=1)\n",
    "    \n",
    "    # Apply feature engineering (same as training)\n",
    "    data_processed = feature_engineering(data_processed)\n",
    "    \n",
    "    # Remove target column if it exists (for prediction on new data)\n",
    "    if 'Rings' in data_processed.columns:\n",
    "        data_processed = data_processed.drop('Rings', axis=1)\n",
    "    \n",
    "    # Apply scaling\n",
    "    data_scaled, _ = scale_features(data_processed, fit_scaler=False, scaler=scaler)\n",
    "    \n",
    "    print(f\"   Preprocessed {len(data_processed)} samples with {len(data_processed.columns)} features\")\n",
    "    \n",
    "    return data_scaled\n",
    "\n",
    "def predict_abalone_age(model: RandomForestRegressor,\n",
    "                       data: pd.DataFrame,\n",
    "                       encoders: Dict,\n",
    "                       scaler: StandardScaler,\n",
    "                       return_confidence: bool = False) -> Dict:\n",
    "    \"\"\"\n",
    "    Make predictions on new abalone data.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        data: New data (raw format)\n",
    "        encoders: Fitted encoders\n",
    "        scaler: Fitted scaler\n",
    "        return_confidence: Whether to return prediction intervals\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Predictions and metadata\n",
    "    \"\"\"\n",
    "    print(f\"\\n🔮 Making predictions for {len(data)} samples...\")\n",
    "    \n",
    "    # Preprocess the data\n",
    "    data_processed = preprocess_new_data(data, encoders, scaler)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(data_processed)\n",
    "    \n",
    "    # Calculate prediction intervals if requested\n",
    "    prediction_results = {\n",
    "        'predictions': predictions,\n",
    "        'num_samples': len(data),\n",
    "        'features_used': list(data_processed.columns)\n",
    "    }\n",
    "    \n",
    "    if return_confidence and hasattr(model, 'estimators_'):\n",
    "        # Calculate prediction intervals using individual trees\n",
    "        tree_predictions = np.array([tree.predict(data_processed) for tree in model.estimators_])\n",
    "        \n",
    "        # Calculate confidence intervals (e.g., 95%)\n",
    "        lower_percentile = np.percentile(tree_predictions, 2.5, axis=0)\n",
    "        upper_percentile = np.percentile(tree_predictions, 97.5, axis=0)\n",
    "        \n",
    "        prediction_results.update({\n",
    "            'confidence_lower': lower_percentile,\n",
    "            'confidence_upper': upper_percentile,\n",
    "            'confidence_width': upper_percentile - lower_percentile\n",
    "        })\n",
    "    \n",
    "    # Convert to age in years (rings + 1.5)\n",
    "    age_predictions = predictions + 1.5\n",
    "    prediction_results['age_years'] = age_predictions\n",
    "    \n",
    "    print(f\"   ✅ Predictions complete!\")\n",
    "    print(f\"   Predicted rings range: {predictions.min():.1f} - {predictions.max():.1f}\")\n",
    "    print(f\"   Predicted age range: {age_predictions.min():.1f} - {age_predictions.max():.1f} years\")\n",
    "    \n",
    "    return prediction_results\n",
    "\n",
    "def create_sample_prediction_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create sample data for demonstration of prediction pipeline.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Sample abalone data\n",
    "    \"\"\"\n",
    "    sample_data = pd.DataFrame({\n",
    "        'Sex': ['M', 'F', 'I'],\n",
    "        'Length': [0.455, 0.53, 0.33],\n",
    "        'Diameter': [0.365, 0.42, 0.255],\n",
    "        'Height': [0.095, 0.135, 0.08],\n",
    "        'Whole weight': [0.514, 0.677, 0.205],\n",
    "        'Shucked weight': [0.2245, 0.2565, 0.0895],\n",
    "        'Viscera weight': [0.101, 0.1415, 0.0395],\n",
    "        'Shell weight': [0.15, 0.21, 0.055]\n",
    "    })\n",
    "    \n",
    "    return sample_data\n",
    "\n",
    "# Demonstrate prediction pipeline\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🔮 PREDICTION PIPELINE DEMO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create sample data for prediction\n",
    "sample_data = create_sample_prediction_data()\n",
    "print(\"Sample data for prediction:\")\n",
    "display(sample_data)\n",
    "\n",
    "# Make predictions\n",
    "prediction_results = predict_abalone_age(\n",
    "    model=model,\n",
    "    data=sample_data,\n",
    "    encoders=encoders,\n",
    "    scaler=feature_scaler,\n",
    "    return_confidence=True\n",
    ")\n",
    "\n",
    "# Display results\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Sex': sample_data['Sex'],\n",
    "    'Length': sample_data['Length'],\n",
    "    'Predicted_Rings': prediction_results['predictions'],\n",
    "    'Predicted_Age_Years': prediction_results['age_years'],\n",
    "    'Confidence_Lower': prediction_results.get('confidence_lower', [None]*len(sample_data)),\n",
    "    'Confidence_Upper': prediction_results.get('confidence_upper', [None]*len(sample_data))\n",
    "})\n",
    "\n",
    "print(f\"\\n🎯 Prediction Results:\")\n",
    "display(predictions_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6972f2f8",
   "metadata": {},
   "source": [
    "## 7. Complete ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81ce03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model and create summary\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Find best model based on test RMSE\n",
    "best_model_name = min(models_results.keys(), key=lambda x: models_results[x]['test_rmse'])\n",
    "best_metrics = models_results[best_model_name]\n",
    "\n",
    "if best_model_name == \"Linear Regression\":\n",
    "    best_model = lr_trained\n",
    "elif best_model_name == \"Random Forest\":\n",
    "    best_model = rf_trained\n",
    "else:\n",
    "    best_model = dt_trained\n",
    "\n",
    "print(f\"🏆 Best performing model: {best_model_name}\")\n",
    "print(f\"📊 Best model metrics:\")\n",
    "for metric, value in best_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# Save the best model\n",
    "models_dir = Path('../models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save model and preprocessor\n",
    "with open(models_dir / 'best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "    \n",
    "with open(models_dir / 'label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "print(f\"\\n💾 Best model saved to: {models_dir}/best_model.pkl\")\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"\udfaf EXPERIMENT SUMMARY\")\n",
    "print(f\"=\"*60)\n",
    "print(f\"📊 Dataset: {df.shape[0]} samples, {df.shape[1]} features\")\n",
    "print(f\"🔧 Preprocessing: Simple label encoding of 'Sex' column\")\n",
    "print(f\"🤖 Models trained: 3 (Linear Regression, Random Forest, Decision Tree)\")\n",
    "print(f\"🏆 Best model: {best_model_name}\")\n",
    "print(f\"📈 Best Test RMSE: {best_metrics['test_rmse']:.4f}\")\n",
    "print(f\"📈 Best Test R²: {best_metrics['test_r2']:.4f}\")\n",
    "print(f\"\\n💡 To view experiments in MLflow UI:\")\n",
    "print(f\"   1. Run: mlflow ui\")\n",
    "print(f\"   2. Open: http://localhost:5000\")\n",
    "print(f\"   3. Browse the 'abalone_age_prediction' experiment\")\n",
    "print(f\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
