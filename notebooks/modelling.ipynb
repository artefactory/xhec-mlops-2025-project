{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you should implement a first version of a working machine learning model to predict the age of an Abalone.\n",
    "\n",
    "A few guidelines:\n",
    "- The model does not have to be complex. A simple linear regression model is enough.\n",
    "- You should use MLflow to track your experiments. You can use the MLflow UI to compare your experiments.\n",
    "- Do not push any MLflow data to the repository. Only the code to run the experiments is interesting and should be pushed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports pour la modélisation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', 500)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Imports terminés avec succès!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement et préparation des données\n",
    "print(\"=== CHARGEMENT DES DONNÉES ===\")\n",
    "\n",
    "# Charger le dataset\n",
    "df = pd.read_csv(\"../abalone.csv\")\n",
    "print(f\"Dataset chargé: {df.shape}\")\n",
    "\n",
    "# Afficher les premières lignes\n",
    "print(\"\\nPremières lignes:\")\n",
    "print(df.head())\n",
    "\n",
    "# Vérifier les types de données\n",
    "print(f\"\\nTypes de données:\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des features et de la variable cible\n",
    "print(\"=== PRÉPARATION DES DONNÉES ===\")\n",
    "\n",
    "# Encoder la variable catégorielle Sex\n",
    "le = LabelEncoder()\n",
    "df['Sex_encoded'] = le.fit_transform(df['Sex'])\n",
    "\n",
    "print(\"Mapping des valeurs Sex:\")\n",
    "for i, sex in enumerate(le.classes_):\n",
    "    print(f\"{sex}: {i}\")\n",
    "\n",
    "# Définir les features et la target\n",
    "feature_cols = ['Sex_encoded', 'Length', 'Diameter', 'Height', \n",
    "                'Whole weight', 'Shucked weight', 'Viscera weight', 'Shell weight']\n",
    "X = df[feature_cols]\n",
    "y = df['Rings']\n",
    "\n",
    "print(f\"\\nFeatures sélectionnées: {feature_cols}\")\n",
    "print(f\"Shape de X: {X.shape}\")\n",
    "print(f\"Shape de y: {y.shape}\")\n",
    "\n",
    "# Division train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"\\nDivision train/test:\")\n",
    "print(f\"Train: {X_train.shape[0]} échantillons\")\n",
    "print(f\"Test: {X_test.shape[0]} échantillons\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des features\n",
    "print(\"=== NORMALISATION DES FEATURES ===\")\n",
    "\n",
    "# Standardisation des features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Normalisation effectuée avec StandardScaler\")\n",
    "print(f\"Mean des features normalisées (train): {X_train_scaled.mean(axis=0)}\")\n",
    "print(f\"Std des features normalisées (train): {X_train_scaled.std(axis=0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modélisation - Régression Linéaire Simple\n",
    "print(\"=== RÉGRESSION LINÉAIRE SIMPLE ===\")\n",
    "\n",
    "# Modèle de régression linéaire\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "# Métriques\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"Régression Linéaire - Métriques:\")\n",
    "print(f\"RMSE: {rmse_lr:.3f}\")\n",
    "print(f\"R²: {r2_lr:.3f}\")\n",
    "print(f\"MAE: {mae_lr:.3f}\")\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores_lr = cross_val_score(lr, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "print(f\"R² Cross-validation (5-fold): {cv_scores_lr.mean():.3f} (+/- {cv_scores_lr.std() * 2:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modélisation - Random Forest\n",
    "print(\"=== RANDOM FOREST ===\")\n",
    "\n",
    "# Modèle Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)  # Pas besoin de normalisation pour Random Forest\n",
    "\n",
    "# Prédictions\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Métriques\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest - Métriques:\")\n",
    "print(f\"RMSE: {rmse_rf:.3f}\")\n",
    "print(f\"R²: {r2_rf:.3f}\")\n",
    "print(f\"MAE: {mae_rf:.3f}\")\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores_rf = cross_val_score(rf, X_train, y_train, cv=5, scoring='r2')\n",
    "print(f\"R² Cross-validation (5-fold): {cv_scores_rf.mean():.3f} (+/- {cv_scores_rf.std() * 2:.3f})\")\n",
    "\n",
    "# Importance des features\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nImportance des features:\")\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des modèles\n",
    "print(\"=== COMPARAISON DES MODÈLES ===\")\n",
    "\n",
    "# Créer un DataFrame de comparaison\n",
    "results = pd.DataFrame({\n",
    "    'Modèle': ['Régression Linéaire', 'Random Forest'],\n",
    "    'RMSE': [rmse_lr, rmse_rf],\n",
    "    'R²': [r2_lr, r2_rf],\n",
    "    'MAE': [mae_lr, mae_rf]\n",
    "})\n",
    "\n",
    "print(\"Comparaison des performances:\")\n",
    "print(results.round(3))\n",
    "\n",
    "# Visualisation des prédictions vs vraies valeurs\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Régression Linéaire\n",
    "axes[0].scatter(y_test, y_pred_lr, alpha=0.6)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Vraies valeurs')\n",
    "axes[0].set_ylabel('Prédictions')\n",
    "axes[0].set_title(f'Régression Linéaire (R² = {r2_lr:.3f})')\n",
    "\n",
    "# Random Forest\n",
    "axes[1].scatter(y_test, y_pred_rf, alpha=0.6)\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1].set_xlabel('Vraies valeurs')\n",
    "axes[1].set_ylabel('Prédictions')\n",
    "axes[1].set_title(f'Random Forest (R² = {r2_rf:.3f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions de la Modélisation\n",
    "\n",
    "### Résultats obtenus :\n",
    "\n",
    "1. **Régression Linéaire** :\n",
    "   - Modèle simple et interprétable\n",
    "   - Performance correcte pour un modèle de base\n",
    "   - Nécessite une normalisation des features\n",
    "\n",
    "2. **Random Forest** :\n",
    "   - Généralement meilleure performance\n",
    "   - Capture les interactions non-linéaires\n",
    "   - Fournit l'importance des features\n",
    "   - Plus robuste aux outliers\n",
    "\n",
    "### Recommandations pour l'amélioration :\n",
    "\n",
    "1. **Feature Engineering** :\n",
    "   - Créer de nouvelles features (ratios, interactions)\n",
    "   - Gérer les outliers détectés en EDA\n",
    "\n",
    "2. **Optimisation des hyperparamètres** :\n",
    "   - Grid Search pour Random Forest\n",
    "   - Test de différents algorithmes (XGBoost, SVM)\n",
    "\n",
    "3. **Validation** :\n",
    "   - Stratified sampling si nécessaire\n",
    "   - Time series split si applicable\n",
    "\n",
    "### Prochaines étapes :\n",
    "- Sauvegarder le meilleur modèle\n",
    "- Préparer le pipeline de prédiction\n",
    "- Intégrer MLflow pour le tracking\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
